
================================================================================
CELL 51 (markdown)
================================================================================

--- Context Cell 49 (code) ---
plot_knn_bound(X, y, n_neighbors=1)
plot_knn_bound(X, y, n_neighbors=10)

--- Context Cell 50 (markdown) ---
### <font color='DarkOrange'>**Задание 1.2 (кросс-проверка, 2 балла)**</font>

Чем отличаются поверхности, полученные при числе соседей 1 и 10? Объясните, чем вызваны данные отличия

--- CURRENT CELL 51 ---
<font color='MediumOrchid'>**Ваши выводы тут:**</font>

================================================================================
CELL 54 (code)
================================================================================

--- Context Cell 52 (markdown) ---
---

--- Context Cell 53 (markdown) ---
### <font color='DarkOrange'>**Задание 1.3 (кросс-проверка, 1 балл)**</font>

Данную проблему может решить нормализация признакового пространства.

Начертите разделяющие поверхности для $KNN$, обученного на нормализованных признаках с помощью реализованных вами нормализаторов. Используйте функцию $plot\_knn\_bound$. Менять функцию $plot\_knn\_bound$ нельзя.

--- CURRENT CELL 54 ---
# your code here

================================================================================
CELL 76 (code)
================================================================================

--- Context Cell 74 (markdown) ---
Мы можем задать такой словарик типа `str` -> `list`, который будет описывать все наши изменения, которые должны будут примениться в `Pipeline` (применяться они будут через класс кросс-валидации)

Если в качестве ключа написать ровно то название, которым мы обозначили шаг в `Pipeline`, то потом появляется возможность программно сопоставить эти два шага и заменить значения в `Pipeline`:

    'normalizer': ['passthrough', MinMaxScaler(), StandardScaler()]

В данном случае у нас в `Pipeline` значения в названии шага `normalizer` будут меняться в соответствии с предложенными вариантам в списке

<font color='LightSteelBlue'>**Пояснение:**</font> `passthrough` - ключевое слово, которые говорит `sklearn` "пропусти этот шаг"

А здесь уже логика чуть посложнее: у класса `KNeighborsRegressor`, который лежит в шаге classifier, при создании можно указать различный набор гиперпараметров, например, тот же n_negihbors. Обращаясь через двойное нижнее подчеркивание появляется возможность на лету изменять значения этих гиперпараметров в классе:

    'classifier__n_neighbors': [1, 5, 10]

Здесь мы говорим "посмотри, что за модель лежит на шаге classifier, и замени у нее гиперпараметр n_neighbors в соответствии с сеткой перебора"

--- Context Cell 75 (markdown) ---
### <font color='DarkOrange'>**Задание 2.1 (кросс, 2 балла)**</font>


Запустите кросс-валидацию на 3 фолдах с помощью класса `GridSearchCV` и метода $fit$ этого модуля. В качестве метрики используйте $R^2$-score (строкое представление в `sklearn` "r2"). Параметры для перебора описаны ниже

--- CURRENT CELL 76 ---
# задаем нужный пайплайн
pipeline = Pipeline([
    ('normalizer', 'passthrough'),
    ('classifier', KNeighborsRegressor())
])

# и сетку перебора параметров
parameters = {
    'classifier__n_neighbors': [1, 5, 10],
    'classifier__metric': ['euclidean', 'cosine'],
    'classifier__weights': ['uniform', 'distance'],
    'normalizer': ['passthrough', MinMaxScaler(), StandardScaler()]
}

grid_search = GridSearchCV(#your params here, n_jobs=-1, verbose=10) # изучите в документации, как нужно вызывать данный класс
# your fit here

================================================================================
CELL 80 (code)
================================================================================

--- Context Cell 78 (code) ---
for elem in zip (grid_search.cv_results_['params'], grid_search.cv_results_['mean_test_score']):
  print(elem)

--- Context Cell 79 (markdown) ---
### <font color='DarkOrange'>**Задание 2.2 (кросс, 1 балл)**</font>

 Какой наибольший $r2\_score$ удалось достичь на кросс-валидации? Какие закономерности вы видите?

 * Обучите модель с наилучшими параметрами на всей обучающей выборке
 * измерьте $r2\_score$ на тестовой выборке.


--- CURRENT CELL 80 ---
from sklearn.metrics import r2_score # изучите самостоятельно, как с помощью этой функции измерять качество
#your code here

================================================================================
CELL 81 (markdown)
================================================================================

--- Context Cell 79 (markdown) ---
### <font color='DarkOrange'>**Задание 2.2 (кросс, 1 балл)**</font>

 Какой наибольший $r2\_score$ удалось достичь на кросс-валидации? Какие закономерности вы видите?

 * Обучите модель с наилучшими параметрами на всей обучающей выборке
 * измерьте $r2\_score$ на тестовой выборке.


--- Context Cell 80 (code) ---
from sklearn.metrics import r2_score # изучите самостоятельно, как с помощью этой функции измерять качество
#your code here

--- CURRENT CELL 81 ---
<font color='MediumOrchid'>**Ваши выводы тут:**</font>
